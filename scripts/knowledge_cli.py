#!/usr/bin/env python3
"""çŸ¥è¯†åº“ç®¡ç† CLI

æä¾›çŸ¥è¯†åº“æ–‡æ¡£çš„ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ·»åŠ ã€å¯¼å…¥ã€åˆ—å‡ºã€æœç´¢ã€åˆ é™¤ã€åˆ·æ–°å’Œå‘é‡ç´¢å¼•ç®¡ç†ã€‚

ç”¨æ³•:
    python knowledge_cli.py add <url>                           # æ·»åŠ å•ä¸ª URL
    python knowledge_cli.py add-file <file>                     # æ·»åŠ æœ¬åœ°æ–‡ä»¶
    python knowledge_cli.py import <file>                       # æ‰¹é‡å¯¼å…¥ URL
    python knowledge_cli.py list                                # åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£
    python knowledge_cli.py search <query>                      # æœç´¢æ–‡æ¡£
    python knowledge_cli.py search --mode semantic <query>      # è¯­ä¹‰æœç´¢
    python knowledge_cli.py search --mode hybrid <query>        # æ··åˆæœç´¢
    python knowledge_cli.py remove <doc_id>                     # åˆ é™¤æ–‡æ¡£
    python knowledge_cli.py refresh [doc_id]                    # åˆ·æ–°æ–‡æ¡£
    python knowledge_cli.py refresh --all                       # åˆ·æ–°æ‰€æœ‰æ–‡æ¡£
    python knowledge_cli.py index build                         # æ„å»ºå‘é‡ç´¢å¼•
    python knowledge_cli.py index rebuild                       # é‡å»ºå‘é‡ç´¢å¼•
    python knowledge_cli.py index stats                         # æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡

ç¤ºä¾‹:
    python knowledge_cli.py add https://example.com
    python knowledge_cli.py add-file ./docs/readme.md
    python knowledge_cli.py import urls.txt
    python knowledge_cli.py search "Python"
    python knowledge_cli.py search --mode semantic --top-k 5 --min-score 0.5 "æœºå™¨å­¦ä¹ "
    python knowledge_cli.py search --mode hybrid --semantic-weight 0.8 "API é…ç½®"
    python knowledge_cli.py index build
    python knowledge_cli.py refresh doc-abc123
"""
import argparse
import asyncio
import sys
import time
from pathlib import Path
from typing import Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from knowledge import Document, KnowledgeManager, KnowledgeStorage  # noqa: E402


class ProgressBar:
    """ç®€å•çš„è¿›åº¦æ¡æ˜¾ç¤ºå™¨"""

    def __init__(self, total: int, description: str = "", width: int = 40):
        """åˆå§‹åŒ–è¿›åº¦æ¡

        Args:
            total: æ€»ä»»åŠ¡æ•°
            description: ä»»åŠ¡æè¿°
            width: è¿›åº¦æ¡å®½åº¦
        """
        self.total = max(total, 1)
        self.current = 0
        self.description = description
        self.width = width
        self.start_time = time.time()

    def update(self, n: int = 1, message: str = "") -> None:
        """æ›´æ–°è¿›åº¦

        Args:
            n: å¢åŠ çš„è¿›åº¦æ•°
            message: å½“å‰ä»»åŠ¡æ¶ˆæ¯
        """
        self.current += n
        self._render(message)

    def _render(self, message: str = "") -> None:
        """æ¸²æŸ“è¿›åº¦æ¡"""
        percent = min(self.current / self.total, 1.0)
        filled = int(self.width * percent)
        bar = "â–ˆ" * filled + "â–‘" * (self.width - filled)

        elapsed = time.time() - self.start_time
        if self.current > 0:
            eta = (elapsed / self.current) * (self.total - self.current)
            time_str = f"ETA: {eta:.0f}s"
        else:
            time_str = "è®¡ç®—ä¸­..."

        status = f"\r{self.description} |{bar}| {self.current}/{self.total} ({percent*100:.1f}%) {time_str}"
        if message:
            # æˆªæ–­è¿‡é•¿çš„æ¶ˆæ¯
            max_msg_len = 40
            if len(message) > max_msg_len:
                message = message[:max_msg_len-3] + "..."
            status += f" - {message}"

        # æ¸…é™¤è¡Œå°¾å¹¶æ‰“å°
        sys.stdout.write(status + " " * 20)
        sys.stdout.flush()

    def finish(self, message: str = "å®Œæˆ") -> None:
        """å®Œæˆè¿›åº¦æ¡"""
        self.current = self.total
        elapsed = time.time() - self.start_time
        print(f"\r{self.description} |{'â–ˆ' * self.width}| {self.total}/{self.total} (100.0%) ç”¨æ—¶: {elapsed:.1f}s - {message}")


class KnowledgeCLI:
    """çŸ¥è¯†åº“ CLI ç®¡ç†å™¨"""

    def __init__(self, kb_name: str = "default"):
        """åˆå§‹åŒ– CLI

        Args:
            kb_name: çŸ¥è¯†åº“åç§°
        """
        self.manager = KnowledgeManager(name=kb_name)
        self.storage = KnowledgeStorage()

    async def add(self, url: str) -> bool:
        """æ·»åŠ å•ä¸ª URL åˆ°çŸ¥è¯†åº“

        Args:
            url: ç›®æ ‡ URL

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ“¥ æ­£åœ¨æ·»åŠ : {url}")

        await self.manager.initialize()
        doc = await self.manager.add_url(url)

        if doc:
            # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            await self.storage.initialize()
            success, message = await self.storage.save_document(doc)

            if success:
                print(f"âœ… æ·»åŠ æˆåŠŸ: {doc.id}")
                print(f"   æ ‡é¢˜: {doc.title or '(æ— æ ‡é¢˜)'}")
                print(f"   å†…å®¹å¤§å°: {len(doc.content)} å­—ç¬¦")
                return True
            else:
                print(f"âš ï¸ ä¿å­˜å¤±è´¥: {message}")
                return False
        else:
            print("âŒ æ·»åŠ å¤±è´¥: æ— æ³•è·å– URL å†…å®¹")
            return False

    async def add_file(self, file_path: str, encoding: str = "utf-8") -> bool:
        """æ·»åŠ æœ¬åœ°æ–‡ä»¶åˆ°çŸ¥è¯†åº“

        æ”¯æŒ .txt, .md, .rst ç­‰æ–‡æœ¬æ ¼å¼ã€‚

        Args:
            file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç ï¼Œé»˜è®¤ utf-8

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        path = Path(file_path)
        if not path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False

        print(f"ğŸ“„ æ­£åœ¨æ·»åŠ æ–‡ä»¶: {file_path}")

        await self.manager.initialize()
        doc = await self.manager.add_file(file_path, encoding=encoding)

        if doc:
            # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            await self.storage.initialize()
            success, message = await self.storage.save_document(doc)

            if success:
                print(f"âœ… æ·»åŠ æˆåŠŸ: {doc.id}")
                print(f"   æ ‡é¢˜: {doc.title or '(æ— æ ‡é¢˜)'}")
                print(f"   å†…å®¹å¤§å°: {len(doc.content)} å­—ç¬¦")
                print(f"   æ–‡ä»¶ç±»å‹: {doc.metadata.get('file_extension', 'unknown')}")
                return True
            else:
                print(f"âš ï¸ ä¿å­˜å¤±è´¥: {message}")
                return False
        else:
            print("âŒ æ·»åŠ å¤±è´¥: æ— æ³•è¯»å–æ–‡ä»¶æˆ–æ ¼å¼ä¸æ”¯æŒ")
            print("   æ”¯æŒçš„æ ¼å¼: .txt, .md, .rst, .text, .markdown")
            return False

    async def import_urls(self, file_path: str) -> int:
        """æ‰¹é‡å¯¼å…¥ URL

        Args:
            file_path: URL æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ª URLï¼‰

        Returns:
            æˆåŠŸæ·»åŠ çš„æ•°é‡
        """
        path = Path(file_path)
        if not path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return 0

        # è¯»å– URL åˆ—è¡¨
        urls = []
        with open(path, encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                if line and not line.startswith("#"):
                    urls.append(line)

        if not urls:
            print("âš ï¸ æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„ URL")
            return 0

        print(f"ğŸ“¥ æ­£åœ¨å¯¼å…¥ {len(urls)} ä¸ª URL...")

        await self.manager.initialize()
        await self.storage.initialize()

        docs = await self.manager.add_urls(urls)

        # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
        success_count = 0
        for doc in docs:
            success, _ = await self.storage.save_document(doc)
            if success:
                success_count += 1
                print(f"  âœ… {doc.id}: {doc.title or doc.url}")

        print(f"\nğŸ“Š å¯¼å…¥å®Œæˆ: {success_count}/{len(urls)} æˆåŠŸ")
        return success_count

    async def list_docs(
        self,
        limit: int = 50,
        offset: int = 0,
        verbose: bool = False,
    ) -> list:
        """åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            offset: èµ·å§‹ä½ç½®
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        await self.storage.initialize()
        entries = await self.storage.list_documents(offset=offset, limit=limit)

        if not entries:
            print("ğŸ“­ çŸ¥è¯†åº“ä¸ºç©º")
            return []

        print(f"ğŸ“š çŸ¥è¯†åº“æ–‡æ¡£åˆ—è¡¨ (å…± {len(entries)} æ¡):\n")
        print(f"{'ID':<16} {'æ ‡é¢˜':<40} {'å¤§å°':>8}")
        print("-" * 70)

        for entry in entries:
            title = entry.title[:37] + "..." if len(entry.title) > 40 else entry.title
            size = f"{entry.content_size:,}"
            print(f"{entry.doc_id:<16} {title:<40} {size:>8}")

            if verbose:
                print(f"    URL: {entry.url}")
                print(f"    æ›´æ–°æ—¶é—´: {entry.updated_at}")
                print()

        return entries

    async def search(
        self,
        query: str,
        limit: int = 10,
        mode: str = "keyword",
        min_score: float = 0.0,
        semantic_weight: float = 0.7,
    ) -> list:
        """æœç´¢æ–‡æ¡£

        Args:
            query: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            mode: æœç´¢æ¨¡å¼ - "keyword"(å…³é”®è¯), "semantic"(è¯­ä¹‰), "hybrid"(æ··åˆ)
            min_score: æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼ (0.0-1.0)
            semantic_weight: æ··åˆæœç´¢ä¸­è¯­ä¹‰æƒé‡ (0.0-1.0)

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        mode_names = {
            "keyword": "å…³é”®è¯",
            "semantic": "è¯­ä¹‰",
            "hybrid": "æ··åˆ",
        }
        mode_display = mode_names.get(mode, mode)
        print(f"ğŸ” {mode_display}æœç´¢: {query}")

        if mode in ("semantic", "hybrid"):
            print(f"   å‚æ•°: top_k={limit}, min_score={min_score}", end="")
            if mode == "hybrid":
                print(f", semantic_weight={semantic_weight}")
            else:
                print()
        print()

        await self.storage.initialize()

        # æ ¹æ®æ¨¡å¼é€‰æ‹©æœç´¢æ–¹æ³•
        if mode == "semantic":
            # ä½¿ç”¨è¯­ä¹‰æœç´¢
            vector_results = await self.storage.search_semantic(
                query,
                top_k=limit,
                min_score=min_score,
            )
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            results = []
            for vr in vector_results:
                from knowledge import SearchResult
                entry = self.storage._index.get(vr.doc_id)
                if entry:
                    results.append(SearchResult(
                        doc_id=vr.doc_id,
                        url=entry.url,
                        title=entry.title,
                        score=vr.score,
                        snippet=vr.content[:100] + "..." if len(vr.content) > 100 else vr.content,
                        match_type="semantic",
                    ))
        elif mode == "hybrid":
            # ä½¿ç”¨æ··åˆæœç´¢
            results = await self.storage.search(query, limit=limit, mode="hybrid")
            # è¿‡æ»¤ä½äºæœ€ä½åˆ†æ•°çš„ç»“æœ
            if min_score > 0:
                results = [r for r in results if r.score >= min_score]
        else:
            # é»˜è®¤å…³é”®è¯æœç´¢
            results = await self.storage.search(query, limit=limit, mode="keyword")

        if not results:
            print("ğŸ“­ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£")
            return []

        print(f"æ‰¾åˆ° {len(results)} æ¡ç»“æœ:\n")

        # è¡¨å¤´
        print(f"{'åºå·':<4} {'åˆ†æ•°':>6} {'åŒ¹é…ç±»å‹':<10} {'æ ‡é¢˜':<40}")
        print("-" * 70)

        for i, result in enumerate(results, 1):
            # æ ¼å¼åŒ–åˆ†æ•°
            score_str = f"{result.score:.3f}" if result.score < 1 else f"{result.score:.1f}"

            # åŒ¹é…ç±»å‹æ ‡è®°
            match_type_display = {
                "semantic": "ğŸ§  è¯­ä¹‰",
                "keyword": "ğŸ”¤ å…³é”®è¯",
                "hybrid": "ğŸ”€ æ··åˆ",
                "exact": "âœ“ ç²¾ç¡®",
                "partial": "~ éƒ¨åˆ†",
            }.get(result.match_type, result.match_type)

            # æˆªæ–­æ ‡é¢˜
            title = result.title or "(æ— æ ‡é¢˜)"
            if len(title) > 38:
                title = title[:35] + "..."

            print(f"{i:<4} {score_str:>6} {match_type_display:<10} {title:<40}")
            print(f"     ID: {result.doc_id}")
            print(f"     URL: {result.url}")
            if result.snippet:
                # æˆªå–å¹¶æ¸…ç†æ‘˜è¦
                snippet = result.snippet.replace("\n", " ")[:100]
                print(f"     æ‘˜è¦: {snippet}...")
            print()

        return results

    async def remove(self, doc_id: str) -> bool:
        """åˆ é™¤æ–‡æ¡£

        Args:
            doc_id: æ–‡æ¡£ ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ—‘ï¸ æ­£åœ¨åˆ é™¤: {doc_id}")

        await self.storage.initialize()

        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨
        if not self.storage.has_document(doc_id):
            print(f"âŒ æ–‡æ¡£ä¸å­˜åœ¨: {doc_id}")
            return False

        success = await self.storage.delete_document(doc_id)

        if success:
            print(f"âœ… åˆ é™¤æˆåŠŸ: {doc_id}")
            return True
        else:
            print("âŒ åˆ é™¤å¤±è´¥")
            return False

    async def refresh(
        self,
        doc_id: Optional[str] = None,
        refresh_all: bool = False,
    ) -> int:
        """åˆ·æ–°æ–‡æ¡£ï¼ˆé‡æ–°è·å– URL å†…å®¹ï¼‰

        Args:
            doc_id: æŒ‡å®šæ–‡æ¡£ ID
            refresh_all: æ˜¯å¦åˆ·æ–°æ‰€æœ‰æ–‡æ¡£

        Returns:
            æˆåŠŸåˆ·æ–°çš„æ•°é‡
        """
        await self.manager.initialize()
        await self.storage.initialize()

        if refresh_all:
            # åˆ·æ–°æ‰€æœ‰æ–‡æ¡£
            entries = await self.storage.list_documents(limit=1000)
            if not entries:
                print("ğŸ“­ çŸ¥è¯†åº“ä¸ºç©ºï¼Œæ— éœ€åˆ·æ–°")
                return 0

            print(f"ğŸ”„ æ­£åœ¨åˆ·æ–°æ‰€æœ‰æ–‡æ¡£ ({len(entries)} ä¸ª)...\n")

            success_count = 0
            for entry in entries:
                print(f"  åˆ·æ–°: {entry.doc_id} ({entry.title or entry.url})")

                # åŠ è½½æ–‡æ¡£è·å– URL
                doc = await self.storage.load_document(entry.doc_id)
                if not doc:
                    print("    âš ï¸ åŠ è½½å¤±è´¥ï¼Œè·³è¿‡")
                    continue

                # åˆ·æ–°
                refreshed_doc = await self.manager.refresh(doc.url)
                if refreshed_doc:
                    # ä¿å­˜æ›´æ–°
                    success, _ = await self.storage.save_document(refreshed_doc, force=True)
                    if success:
                        success_count += 1
                        print("    âœ… æˆåŠŸ")
                    else:
                        print("    âš ï¸ ä¿å­˜å¤±è´¥")
                else:
                    print("    âŒ è·å–å¤±è´¥")

            print(f"\nğŸ“Š åˆ·æ–°å®Œæˆ: {success_count}/{len(entries)} æˆåŠŸ")
            return success_count

        elif doc_id:
            # åˆ·æ–°æŒ‡å®šæ–‡æ¡£
            print(f"ğŸ”„ æ­£åœ¨åˆ·æ–°: {doc_id}")

            doc = await self.storage.load_document(doc_id)
            if not doc:
                print(f"âŒ æ–‡æ¡£ä¸å­˜åœ¨: {doc_id}")
                return 0

            refreshed_doc = await self.manager.refresh(doc.url)
            if refreshed_doc:
                success, _ = await self.storage.save_document(refreshed_doc, force=True)
                if success:
                    print(f"âœ… åˆ·æ–°æˆåŠŸ: {doc_id}")
                    print(f"   å†…å®¹å¤§å°: {len(refreshed_doc.content)} å­—ç¬¦")
                    return 1
                else:
                    print("âš ï¸ ä¿å­˜å¤±è´¥")
                    return 0
            else:
                print("âŒ åˆ·æ–°å¤±è´¥: æ— æ³•è·å– URL å†…å®¹")
                return 0

        else:
            print("âŒ è¯·æŒ‡å®šæ–‡æ¡£ ID æˆ–ä½¿ç”¨ --all åˆ·æ–°æ‰€æœ‰æ–‡æ¡£")
            return 0

    async def stats(self) -> dict:
        """æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        await self.storage.initialize()
        stats = await self.storage.get_stats()

        print("ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡:\n")
        print(f"  æ–‡æ¡£æ•°é‡: {stats['document_count']}")
        print(f"  æ€»å†…å®¹å¤§å°: {stats['total_content_size']:,} å­—ç¬¦")
        print(f"  åˆ†å—æ€»æ•°: {stats['total_chunk_count']}")
        print(f"  å­˜å‚¨è·¯å¾„: {stats['storage_path']}")

        return stats

    async def index_build(self) -> dict[str, Any]:
        """æ„å»ºå‘é‡ç´¢å¼•

        ä¸ºæ‰€æœ‰æœªç´¢å¼•çš„æ–‡æ¡£æ„å»ºå‘é‡ç´¢å¼•ã€‚

        Returns:
            æ„å»ºç»“æœç»Ÿè®¡
        """
        print("ğŸ”§ æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•...\n")

        await self.storage.initialize()

        # è·å–æ‰€æœ‰æ–‡æ¡£
        entries = await self.storage.list_documents(limit=10000)
        if not entries:
            print("ğŸ“­ çŸ¥è¯†åº“ä¸ºç©ºï¼Œæ— éœ€æ„å»ºç´¢å¼•")
            return {"indexed": 0, "failed": 0, "total": 0}

        # æ£€æŸ¥å‘é‡å­˜å‚¨
        if self.storage._vector_store is None:
            print("âŒ å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ä¾èµ–")
            return {"indexed": 0, "failed": 0, "total": len(entries), "error": "å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–"}

        # è·å–å·²ç´¢å¼•çš„æ–‡æ¡£ ID
        indexed_doc_ids = set(self.storage._vector_store._doc_chunk_mapping.keys())

        # æ‰¾å‡ºæœªç´¢å¼•çš„æ–‡æ¡£
        unindexed_entries = [e for e in entries if e.doc_id not in indexed_doc_ids]

        if not unindexed_entries:
            print("âœ… æ‰€æœ‰æ–‡æ¡£å·²å®Œæˆç´¢å¼•ï¼Œæ— éœ€é‡æ–°æ„å»º")
            return {"indexed": 0, "failed": 0, "total": len(entries), "already_indexed": len(indexed_doc_ids)}

        print(f"ğŸ“Š å‘ç° {len(unindexed_entries)} ä¸ªå¾…ç´¢å¼•æ–‡æ¡£ (å·²ç´¢å¼•: {len(indexed_doc_ids)})\n")

        # åˆ›å»ºè¿›åº¦æ¡
        progress = ProgressBar(len(unindexed_entries), "æ„å»ºç´¢å¼•")

        indexed = 0
        failed = 0

        for entry in unindexed_entries:
            doc = await self.storage.load_document(entry.doc_id)
            if doc:
                try:
                    success = await self.storage._vector_store.index_document(doc)
                    if success:
                        indexed += 1
                        progress.update(1, f"âœ“ {entry.title[:30] if entry.title else entry.doc_id}")
                    else:
                        failed += 1
                        progress.update(1, f"âœ— {entry.doc_id}")
                except Exception:
                    failed += 1
                    progress.update(1, "âœ— é”™è¯¯")
            else:
                failed += 1
                progress.update(1, "âœ— åŠ è½½å¤±è´¥")

        progress.finish(f"ç´¢å¼•: {indexed}, å¤±è´¥: {failed}")

        print("\nğŸ“Š ç´¢å¼•æ„å»ºå®Œæˆ:")
        print(f"   æˆåŠŸç´¢å¼•: {indexed}")
        print(f"   ç´¢å¼•å¤±è´¥: {failed}")
        print(f"   æ–‡æ¡£æ€»æ•°: {len(entries)}")

        return {"indexed": indexed, "failed": failed, "total": len(entries)}

    async def index_rebuild(self) -> dict[str, Any]:
        """é‡å»ºå‘é‡ç´¢å¼•

        æ¸…ç©ºç°æœ‰ç´¢å¼•å¹¶é‡æ–°ç´¢å¼•æ‰€æœ‰æ–‡æ¡£ã€‚

        Returns:
            é‡å»ºç»“æœç»Ÿè®¡
        """
        print("ğŸ”„ æ­£åœ¨é‡å»ºå‘é‡ç´¢å¼•...\n")
        print("âš ï¸ æ³¨æ„: è¿™å°†æ¸…ç©ºç°æœ‰ç´¢å¼•å¹¶é‡æ–°æ„å»º\n")

        await self.storage.initialize()

        # è·å–æ‰€æœ‰æ–‡æ¡£
        entries = await self.storage.list_documents(limit=10000)
        if not entries:
            print("ğŸ“­ çŸ¥è¯†åº“ä¸ºç©ºï¼Œæ— éœ€é‡å»ºç´¢å¼•")
            return {"indexed": 0, "failed": 0, "total": 0}

        # æ£€æŸ¥å‘é‡å­˜å‚¨
        if self.storage._vector_store is None:
            print("âŒ å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ä¾èµ–")
            return {"indexed": 0, "failed": 0, "total": len(entries), "error": "å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–"}

        print(f"ğŸ“Š å‡†å¤‡é‡å»º {len(entries)} ä¸ªæ–‡æ¡£çš„ç´¢å¼•\n")

        # åŠ è½½æ‰€æœ‰æ–‡æ¡£
        documents: list[Document] = []
        load_progress = ProgressBar(len(entries), "åŠ è½½æ–‡æ¡£")

        for entry in entries:
            doc = await self.storage.load_document(entry.doc_id)
            if doc:
                documents.append(doc)
                load_progress.update(1, f"âœ“ {entry.title[:30] if entry.title else entry.doc_id}")
            else:
                load_progress.update(1, f"âœ— {entry.doc_id}")

        load_progress.finish(f"å·²åŠ è½½ {len(documents)}/{len(entries)} ä¸ªæ–‡æ¡£")
        print()

        if not documents:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ–‡æ¡£è¿›è¡Œç´¢å¼•")
            return {"indexed": 0, "failed": len(entries), "total": len(entries)}

        # é‡å»ºç´¢å¼•
        index_progress = ProgressBar(len(documents), "é‡å»ºç´¢å¼•")

        # æ¸…ç©ºç°æœ‰ç´¢å¼•
        await self.storage._vector_store._vector_store.clear()
        self.storage._vector_store._doc_chunk_mapping.clear()

        indexed = 0
        failed = 0

        for doc in documents:
            try:
                success = await self.storage._vector_store.index_document(doc)
                if success:
                    indexed += 1
                    title = doc.title[:30] if doc.title else doc.id
                    index_progress.update(1, f"âœ“ {title}")
                else:
                    failed += 1
                    index_progress.update(1, f"âœ— {doc.id}")
            except Exception:
                failed += 1
                index_progress.update(1, "âœ— é”™è¯¯")

        index_progress.finish(f"ç´¢å¼•: {indexed}, å¤±è´¥: {failed}")

        print("\nğŸ“Š ç´¢å¼•é‡å»ºå®Œæˆ:")
        print(f"   æˆåŠŸç´¢å¼•: {indexed}")
        print(f"   ç´¢å¼•å¤±è´¥: {failed}")
        print(f"   æ–‡æ¡£æ€»æ•°: {len(entries)}")

        return {"indexed": indexed, "failed": failed, "total": len(entries)}

    async def index_stats(self) -> dict[str, Any]:
        """æ˜¾ç¤ºå‘é‡ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        print("ğŸ“Š å‘é‡ç´¢å¼•ç»Ÿè®¡:\n")

        await self.storage.initialize()

        # æ£€æŸ¥å‘é‡å­˜å‚¨
        if self.storage._vector_store is None:
            print("âŒ å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–")
            return {"error": "å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–"}

        try:
            stats = await self.storage._vector_store.get_stats()

            print(f"  åˆå§‹åŒ–çŠ¶æ€: {'âœ“ å·²åˆå§‹åŒ–' if stats.get('initialized') else 'âœ— æœªåˆå§‹åŒ–'}")
            print(f"  é›†åˆåç§°: {stats.get('collection_name', 'N/A')}")
            print(f"  å·²ç´¢å¼•æ–‡æ¡£æ•°: {stats.get('document_count', 0)}")
            print(f"  å·²ç´¢å¼•åˆ†å—æ•°: {stats.get('chunk_count', 0)}")
            print(f"  åµŒå…¥æ¨¡å‹: {stats.get('embedding_model', 'N/A')}")
            print(f"  åµŒå…¥ç»´åº¦: {stats.get('embedding_dimension', 0)}")
            print(f"  å­˜å‚¨è·¯å¾„: {stats.get('persist_directory', 'N/A')}")
            print(f"  æŒä¹…åŒ–: {'âœ“' if stats.get('is_persistent') else 'âœ—'}")
            print(f"  ç›¸ä¼¼åº¦åº¦é‡: {stats.get('metric', 'N/A')}")

            # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
            cache_stats = stats.get('cache_stats', {})
            if cache_stats:
                print("\n  åµŒå…¥ç¼“å­˜ç»Ÿè®¡:")
                print(f"    ç¼“å­˜å¤§å°: {cache_stats.get('memory_cache_size', 0)}")
                print(f"    å‘½ä¸­æ¬¡æ•°: {cache_stats.get('hits', 0)}")
                print(f"    æœªå‘½ä¸­æ¬¡æ•°: {cache_stats.get('misses', 0)}")
                hit_rate = cache_stats.get('hit_rate', 0)
                print(f"    å‘½ä¸­ç‡: {hit_rate:.1%}")

            # ä¸å­˜å‚¨æ–‡æ¡£å¯¹æ¯”
            storage_count = len(self.storage._index)
            indexed_count = stats.get('document_count', 0)
            if storage_count != indexed_count:
                print(f"\n  âš ï¸ ç´¢å¼•ä¸åŒæ­¥: å­˜å‚¨ {storage_count} ä¸ªæ–‡æ¡£ï¼Œå·²ç´¢å¼• {indexed_count} ä¸ª")
                print("     å»ºè®®è¿è¡Œ: python knowledge_cli.py index build")
            else:
                print(f"\n  âœ“ ç´¢å¼•åŒæ­¥: æ‰€æœ‰ {storage_count} ä¸ªæ–‡æ¡£å·²ç´¢å¼•")

            return stats

        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)}


def create_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        prog="knowledge_cli",
        description="çŸ¥è¯†åº“ç®¡ç† CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s add https://example.com           æ·»åŠ  URL
  %(prog)s add-file ./docs/readme.md         æ·»åŠ æœ¬åœ°æ–‡ä»¶
  %(prog)s import urls.txt                   æ‰¹é‡å¯¼å…¥
  %(prog)s list                              åˆ—å‡ºæ–‡æ¡£
  %(prog)s list -v                           åˆ—å‡ºæ–‡æ¡£ï¼ˆè¯¦ç»†ï¼‰
  %(prog)s search "Python"                   å…³é”®è¯æœç´¢
  %(prog)s search --mode semantic "æœºå™¨å­¦ä¹ "  è¯­ä¹‰æœç´¢
  %(prog)s search --mode hybrid "API"        æ··åˆæœç´¢
  %(prog)s remove doc-abc123                 åˆ é™¤æ–‡æ¡£
  %(prog)s refresh doc-abc123                åˆ·æ–°æŒ‡å®šæ–‡æ¡£
  %(prog)s refresh --all                     åˆ·æ–°æ‰€æœ‰æ–‡æ¡£
  %(prog)s stats                             æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
  %(prog)s index build                       æ„å»ºå‘é‡ç´¢å¼•
  %(prog)s index rebuild                     é‡å»ºå‘é‡ç´¢å¼•
  %(prog)s index stats                       æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡
        """,
    )

    parser.add_argument(
        "--kb-name",
        default="default",
        help="çŸ¥è¯†åº“åç§° (é»˜è®¤: default)",
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # add å‘½ä»¤
    add_parser = subparsers.add_parser("add", help="æ·»åŠ å•ä¸ª URL")
    add_parser.add_argument("url", help="ç›®æ ‡ URL")

    # add-file å‘½ä»¤
    add_file_parser = subparsers.add_parser("add-file", help="æ·»åŠ æœ¬åœ°æ–‡ä»¶")
    add_file_parser.add_argument("file", help="æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .txt, .md, .rst ç­‰ï¼‰")
    add_file_parser.add_argument(
        "--encoding",
        default="utf-8",
        help="æ–‡ä»¶ç¼–ç  (é»˜è®¤: utf-8)"
    )

    # import å‘½ä»¤
    import_parser = subparsers.add_parser("import", help="æ‰¹é‡å¯¼å…¥ URL")
    import_parser.add_argument("file", help="URL æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ª URLï¼‰")

    # list å‘½ä»¤
    list_parser = subparsers.add_parser("list", help="åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£")
    list_parser.add_argument("-n", "--limit", type=int, default=50, help="è¿”å›æ•°é‡é™åˆ¶")
    list_parser.add_argument("--offset", type=int, default=0, help="èµ·å§‹ä½ç½®")
    list_parser.add_argument("-v", "--verbose", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")

    # search å‘½ä»¤
    search_parser = subparsers.add_parser("search", help="æœç´¢æ–‡æ¡£")
    search_parser.add_argument("query", help="æœç´¢å…³é”®è¯")
    search_parser.add_argument(
        "-n", "--limit", "--top-k",
        type=int,
        default=10,
        dest="limit",
        help="è¿”å›ç»“æœæ•°é‡ (é»˜è®¤: 10)"
    )
    search_parser.add_argument(
        "--mode",
        choices=["keyword", "semantic", "hybrid"],
        default="keyword",
        help="æœç´¢æ¨¡å¼: keyword(å…³é”®è¯), semantic(è¯­ä¹‰), hybrid(æ··åˆ) (é»˜è®¤: keyword)"
    )
    search_parser.add_argument(
        "--min-score",
        type=float,
        default=0.0,
        help="æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼ (0.0-1.0, é»˜è®¤: 0.0)"
    )
    search_parser.add_argument(
        "--semantic-weight",
        type=float,
        default=0.7,
        help="æ··åˆæœç´¢ä¸­è¯­ä¹‰æƒé‡ (0.0-1.0, é»˜è®¤: 0.7)"
    )

    # remove å‘½ä»¤
    remove_parser = subparsers.add_parser("remove", help="åˆ é™¤æ–‡æ¡£")
    remove_parser.add_argument("doc_id", help="æ–‡æ¡£ ID")

    # refresh å‘½ä»¤
    refresh_parser = subparsers.add_parser("refresh", help="åˆ·æ–°æ–‡æ¡£")
    refresh_parser.add_argument("doc_id", nargs="?", help="æ–‡æ¡£ ID")
    refresh_parser.add_argument("--all", action="store_true", dest="refresh_all", help="åˆ·æ–°æ‰€æœ‰æ–‡æ¡£")

    # stats å‘½ä»¤
    subparsers.add_parser("stats", help="æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯")

    # index å‘½ä»¤ç»„
    index_parser = subparsers.add_parser("index", help="å‘é‡ç´¢å¼•ç®¡ç†")
    index_subparsers = index_parser.add_subparsers(dest="index_command", help="ç´¢å¼•å­å‘½ä»¤")

    # index build å­å‘½ä»¤
    index_subparsers.add_parser("build", help="ä¸ºæ‰€æœ‰æœªç´¢å¼•çš„æ–‡æ¡£æ„å»ºå‘é‡ç´¢å¼•")

    # index rebuild å­å‘½ä»¤
    index_subparsers.add_parser("rebuild", help="æ¸…ç©ºå¹¶é‡å»ºæ‰€æœ‰æ–‡æ¡£çš„å‘é‡ç´¢å¼•")

    # index stats å­å‘½ä»¤
    index_subparsers.add_parser("stats", help="æ˜¾ç¤ºå‘é‡ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯")

    return parser


async def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    cli = KnowledgeCLI(kb_name=args.kb_name)

    try:
        if args.command == "add":
            success = await cli.add(args.url)
            return 0 if success else 1

        elif args.command == "add-file":
            success = await cli.add_file(args.file, encoding=args.encoding)
            return 0 if success else 1

        elif args.command == "import":
            count = await cli.import_urls(args.file)
            return 0 if count > 0 else 1

        elif args.command == "list":
            await cli.list_docs(
                limit=args.limit,
                offset=args.offset,
                verbose=args.verbose,
            )
            return 0

        elif args.command == "search":
            results = await cli.search(
                query=args.query,
                limit=args.limit,
                mode=args.mode,
                min_score=args.min_score,
                semantic_weight=args.semantic_weight,
            )
            return 0 if results else 1

        elif args.command == "remove":
            success = await cli.remove(args.doc_id)
            return 0 if success else 1

        elif args.command == "refresh":
            count = await cli.refresh(
                doc_id=args.doc_id,
                refresh_all=args.refresh_all,
            )
            return 0 if count > 0 else 1

        elif args.command == "stats":
            await cli.stats()
            return 0

        elif args.command == "index":
            # å¤„ç† index å­å‘½ä»¤
            if not hasattr(args, 'index_command') or not args.index_command:
                # æ²¡æœ‰æŒ‡å®šå­å‘½ä»¤ï¼Œæ˜¾ç¤ºå¸®åŠ©
                print("ç”¨æ³•: knowledge_cli.py index {build,rebuild,stats}")
                print("\nå¯ç”¨çš„ç´¢å¼•å­å‘½ä»¤:")
                print("  build    ä¸ºæ‰€æœ‰æœªç´¢å¼•çš„æ–‡æ¡£æ„å»ºå‘é‡ç´¢å¼•")
                print("  rebuild  æ¸…ç©ºå¹¶é‡å»ºæ‰€æœ‰æ–‡æ¡£çš„å‘é‡ç´¢å¼•")
                print("  stats    æ˜¾ç¤ºå‘é‡ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯")
                return 1

            if args.index_command == "build":
                result = await cli.index_build()
                return 0 if result.get("indexed", 0) > 0 or result.get("already_indexed", 0) > 0 else 1

            elif args.index_command == "rebuild":
                result = await cli.index_rebuild()
                return 0 if result.get("indexed", 0) > 0 else 1

            elif args.index_command == "stats":
                await cli.index_stats()
                return 0

            else:
                print(f"æœªçŸ¥çš„ç´¢å¼•å­å‘½ä»¤: {args.index_command}")
                return 1

        else:
            parser.print_help()
            return 1

    except KeyboardInterrupt:
        print("\nâš ï¸ æ“ä½œå·²å–æ¶ˆ")
        return 130
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
