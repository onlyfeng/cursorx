"""ç«¯åˆ°ç«¯é”™è¯¯å¤„ç†æµ‹è¯•

éªŒè¯ç³»ç»Ÿåœ¨å„ç§é”™è¯¯åœºæ™¯ä¸‹çš„è¡Œä¸ºï¼ŒåŒ…æ‹¬ï¼š
- è§„åˆ’é˜¶æ®µé”™è¯¯
- æ‰§è¡Œé˜¶æ®µé”™è¯¯
- è¯„å®¡é˜¶æ®µé”™è¯¯
- æäº¤é˜¶æ®µé”™è¯¯
- è¾¹ç•Œæ¡ä»¶

ä½¿ç”¨ Mock æ›¿ä»£çœŸå® Cursor CLI è°ƒç”¨
"""

import asyncio
from typing import Any
from unittest.mock import AsyncMock, patch

import pytest

from agents.reviewer import ReviewDecision
from coordinator.orchestrator import Orchestrator, OrchestratorConfig


class TestPlanningErrors:
    """è§„åˆ’é˜¶æ®µé”™è¯¯æµ‹è¯•"""

    @pytest.fixture
    def orchestrator(self) -> Orchestrator:
        """åˆ›å»ºæµ‹è¯•ç”¨ Orchestrator"""
        config = OrchestratorConfig(
            working_directory=".",
            max_iterations=3,
            worker_pool_size=1,
            enable_auto_commit=False,
        )
        return Orchestrator(config)

    @pytest.mark.asyncio
    async def test_empty_plan_result(self, orchestrator: Orchestrator) -> None:
        """è§„åˆ’è¿”å›ç©ºä»»åŠ¡åˆ—è¡¨"""
        # è§„åˆ’è¿”å›ç©ºä»»åŠ¡åˆ—è¡¨
        mock_plan_result = {
            "success": True,
            "tasks": [],
        }

        # è¯„å®¡åº”è¯¥ä¹Ÿè¢«è°ƒç”¨ï¼ˆå³ä½¿æ²¡æœ‰ä»»åŠ¡ï¼‰
        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 100,
            "summary": "æ— ä»»åŠ¡éœ€è¦æ‰§è¡Œ",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            result = await orchestrator.run("ç©ºä»»åŠ¡æµ‹è¯•")

            # éªŒè¯ç»“æœ
            assert result["total_tasks_created"] == 0
            # è§„åˆ’æˆåŠŸä½†æ²¡æœ‰ä»»åŠ¡
            mock_planner.assert_called()

    @pytest.mark.asyncio
    async def test_invalid_plan_json(self, orchestrator: Orchestrator) -> None:
        """è§„åˆ’è¿”å›æ— æ•ˆ JSON ç»“æ„"""
        # è¿”å›ä¸ç¬¦åˆé¢„æœŸç»“æ„çš„ç»“æœ
        mock_plan_result = {
            "success": True,
            "tasks": "è¿™ä¸æ˜¯ä¸€ä¸ªåˆ—è¡¨",  # é”™è¯¯: tasks åº”è¯¥æ˜¯åˆ—è¡¨
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 0,
            "summary": "è§„åˆ’æ ¼å¼é”™è¯¯",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            # åº”è¯¥èƒ½å¤Ÿå¤„ç†æ— æ•ˆæ ¼å¼è€Œä¸å´©æºƒ
            result = await orchestrator.run("æ— æ•ˆJSONæµ‹è¯•")

            # éªŒè¯ç³»ç»Ÿèƒ½å¤Ÿå®¹é”™å¤„ç†
            assert "error" in result or result["total_tasks_created"] == 0

    @pytest.mark.asyncio
    async def test_planner_timeout(self, orchestrator: Orchestrator) -> None:
        """è§„åˆ’å™¨è¶…æ—¶"""

        async def slow_planner(*args: Any, **kwargs: Any) -> dict[str, Any]:
            await asyncio.sleep(10)  # æ¨¡æ‹Ÿè¶…æ—¶
            return {"success": True, "tasks": []}

        with patch.object(orchestrator.planner, "execute", side_effect=asyncio.TimeoutError()):
            # è¶…æ—¶åº”è¯¥å¯¼è‡´è§„åˆ’å¤±è´¥
            result = await orchestrator.run("è¶…æ—¶æµ‹è¯•")

            # éªŒè¯è¿”å›é”™è¯¯
            assert result.get("success") is False or result.get("error") is not None

    @pytest.mark.asyncio
    async def test_planner_exception(self, orchestrator: Orchestrator) -> None:
        """è§„åˆ’å™¨å¼‚å¸¸"""
        with patch.object(orchestrator.planner, "execute", side_effect=RuntimeError("è§„åˆ’å™¨å†…éƒ¨é”™è¯¯")):
            result = await orchestrator.run("å¼‚å¸¸æµ‹è¯•")

            # éªŒè¯é”™è¯¯è¢«æ­£ç¡®æ•è·å’Œè®°å½•
            assert result.get("success") is False
            assert "error" in result


class TestExecutionErrors:
    """æ‰§è¡Œé˜¶æ®µé”™è¯¯æµ‹è¯•"""

    @pytest.fixture
    def orchestrator(self) -> Orchestrator:
        """åˆ›å»ºæµ‹è¯•ç”¨ Orchestrator"""
        config = OrchestratorConfig(
            working_directory=".",
            max_iterations=2,
            worker_pool_size=2,
            enable_auto_commit=False,
        )
        return Orchestrator(config)

    @pytest.mark.asyncio
    async def test_all_tasks_fail(self, orchestrator: Orchestrator) -> None:
        """æ‰€æœ‰ä»»åŠ¡å¤±è´¥"""
        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "å¤±è´¥ä»»åŠ¡1",
                    "description": "ä¼šå¤±è´¥çš„ä»»åŠ¡",
                    "instruction": "æ‰§è¡Œå¤±è´¥æ“ä½œ",
                    "target_files": ["fail1.py"],
                },
                {
                    "type": "implement",
                    "title": "å¤±è´¥ä»»åŠ¡2",
                    "description": "ä¹Ÿä¼šå¤±è´¥çš„ä»»åŠ¡",
                    "instruction": "æ‰§è¡Œå¦ä¸€ä¸ªå¤±è´¥æ“ä½œ",
                    "target_files": ["fail2.py"],
                },
            ],
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.ABORT,
            "score": 0,
            "summary": "æ‰€æœ‰ä»»åŠ¡éƒ½å¤±è´¥äº†",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            # æ¨¡æ‹Ÿæ‰€æœ‰ä»»åŠ¡å¤±è´¥
            async def simulate_all_fail(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.fail("æ¨¡æ‹Ÿæ‰§è¡Œå¤±è´¥")

            mock_workers.side_effect = simulate_all_fail

            result = await orchestrator.run("å…¨éƒ¨å¤±è´¥æµ‹è¯•")

            # éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½è¢«æ ‡è®°ä¸ºå¤±è´¥
            assert result["total_tasks_failed"] == 2
            assert result["total_tasks_completed"] == 0

    @pytest.mark.asyncio
    async def test_partial_task_failure(self, orchestrator: Orchestrator) -> None:
        """éƒ¨åˆ†ä»»åŠ¡å¤±è´¥"""
        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "æˆåŠŸä»»åŠ¡",
                    "description": "ä¼šæˆåŠŸ",
                    "instruction": "åˆ›å»º success.py",
                    "target_files": ["success.py"],
                },
                {
                    "type": "implement",
                    "title": "å¤±è´¥ä»»åŠ¡",
                    "description": "ä¼šå¤±è´¥",
                    "instruction": "åˆ›å»º fail.py",
                    "target_files": ["fail.py"],
                },
            ],
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 50,
            "summary": "éƒ¨åˆ†ä»»åŠ¡å®Œæˆ",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            # æ¨¡æ‹Ÿéƒ¨åˆ†æˆåŠŸéƒ¨åˆ†å¤±è´¥
            async def simulate_partial(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for i, task in enumerate(tasks):
                    if i == 0:
                        task.complete({"output": "æˆåŠŸ"})
                    else:
                        task.fail("å¤±è´¥åŸå› ")

            mock_workers.side_effect = simulate_partial

            result = await orchestrator.run("éƒ¨åˆ†å¤±è´¥æµ‹è¯•")

            assert result["total_tasks_completed"] == 1
            assert result["total_tasks_failed"] == 1

    @pytest.mark.asyncio
    async def test_task_timeout(self, orchestrator: Orchestrator) -> None:
        """ä»»åŠ¡æ‰§è¡Œè¶…æ—¶"""
        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "è¶…æ—¶ä»»åŠ¡",
                    "description": "æ‰§è¡Œè¶…æ—¶",
                    "instruction": "æ‰§è¡Œè€—æ—¶æ“ä½œ",
                    "target_files": ["timeout.py"],
                },
            ],
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.ABORT,
            "score": 0,
            "summary": "ä»»åŠ¡è¶…æ—¶",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            # æ¨¡æ‹Ÿä»»åŠ¡è¶…æ—¶
            async def simulate_timeout(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.fail("æ‰§è¡Œè¶…æ—¶")

            mock_workers.side_effect = simulate_timeout

            result = await orchestrator.run("è¶…æ—¶ä»»åŠ¡æµ‹è¯•")

            assert result["total_tasks_failed"] >= 1

    @pytest.mark.asyncio
    async def test_worker_crash_recovery(self, orchestrator: Orchestrator) -> None:
        """Worker å´©æºƒæ¢å¤"""
        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "å´©æºƒåæ¢å¤ä»»åŠ¡",
                    "description": "Worker å´©æºƒåéœ€æ¢å¤",
                    "instruction": "æ‰§è¡Œä»»åŠ¡",
                    "target_files": ["recover.py"],
                },
            ],
        }

        crash_count = 0

        async def simulate_crash_then_success(queue: Any, iteration_id: int) -> None:
            nonlocal crash_count
            tasks = queue.get_tasks_by_iteration(iteration_id)
            for task in tasks:
                if crash_count == 0:
                    crash_count += 1
                    # ç¬¬ä¸€æ¬¡æ¨¡æ‹Ÿå´©æºƒ
                    raise RuntimeError("Worker å´©æºƒ")
                else:
                    # åç»­æ¢å¤æˆåŠŸ
                    task.complete({"output": "æ¢å¤åå®Œæˆ"})

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 80,
            "summary": "å´©æºƒåæ¢å¤æˆåŠŸ",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            # ç¬¬ä¸€æ¬¡å´©æºƒï¼Œç¬¬äºŒæ¬¡æˆåŠŸ
            mock_workers.side_effect = simulate_crash_then_success

            # ç³»ç»Ÿåº”è¯¥èƒ½å¤„ç† Worker å´©æºƒ
            result = await orchestrator.run("å´©æºƒæ¢å¤æµ‹è¯•")

            # éªŒè¯ç³»ç»Ÿæ­£ç¡®è®°å½•äº†çŠ¶æ€
            assert "iterations_completed" in result


class TestReviewErrors:
    """è¯„å®¡é˜¶æ®µé”™è¯¯æµ‹è¯•"""

    @pytest.fixture
    def orchestrator(self) -> Orchestrator:
        """åˆ›å»ºæµ‹è¯•ç”¨ Orchestrator"""
        config = OrchestratorConfig(
            working_directory=".",
            max_iterations=2,
            worker_pool_size=1,
            enable_auto_commit=False,
        )
        return Orchestrator(config)

    @pytest.mark.asyncio
    async def test_review_timeout(self, orchestrator: Orchestrator) -> None:
        """è¯„å®¡è¶…æ—¶"""
        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "å¾…è¯„å®¡ä»»åŠ¡",
                    "description": "ä»»åŠ¡æè¿°",
                    "instruction": "æ‰§è¡Œä»»åŠ¡",
                    "target_files": ["file.py"],
                },
            ],
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", side_effect=asyncio.TimeoutError()),
        ):
            mock_planner.return_value = mock_plan_result

            async def simulate_complete(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.complete({"output": "å®Œæˆ"})

            mock_workers.side_effect = simulate_complete

            result = await orchestrator.run("è¯„å®¡è¶…æ—¶æµ‹è¯•")

            # è¯„å®¡è¶…æ—¶åº”è¯¥å¯¼è‡´æ•´ä½“å¤±è´¥
            assert result.get("success") is False

    @pytest.mark.asyncio
    async def test_invalid_review_decision(self, orchestrator: Orchestrator) -> None:
        """æ— æ•ˆè¯„å®¡å†³ç­–"""
        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "ä»»åŠ¡",
                    "description": "æè¿°",
                    "instruction": "æ‰§è¡Œ",
                    "target_files": ["file.py"],
                },
            ],
        }

        # è¿”å›æ— æ•ˆçš„å†³ç­–
        mock_review_result = {
            "success": True,
            "decision": "INVALID_DECISION",  # æ— æ•ˆå†³ç­–
            "score": 50,
            "summary": "è¯„å®¡å®Œæˆ",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            async def simulate_complete(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.complete({"output": "å®Œæˆ"})

            mock_workers.side_effect = simulate_complete

            # ç³»ç»Ÿåº”è¯¥èƒ½å¤„ç†æ— æ•ˆå†³ç­–
            result = await orchestrator.run("æ— æ•ˆå†³ç­–æµ‹è¯•")

            # éªŒè¯ç³»ç»Ÿèƒ½å®¹é”™å¤„ç†
            assert "iterations_completed" in result

    @pytest.mark.asyncio
    async def test_review_exception(self, orchestrator: Orchestrator) -> None:
        """è¯„å®¡å™¨å¼‚å¸¸"""
        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "ä»»åŠ¡",
                    "description": "æè¿°",
                    "instruction": "æ‰§è¡Œ",
                    "target_files": ["file.py"],
                },
            ],
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", side_effect=RuntimeError("è¯„å®¡å™¨å†…éƒ¨é”™è¯¯")),
        ):
            mock_planner.return_value = mock_plan_result

            async def simulate_complete(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.complete({"output": "å®Œæˆ"})

            mock_workers.side_effect = simulate_complete

            result = await orchestrator.run("è¯„å®¡å¼‚å¸¸æµ‹è¯•")

            # å¼‚å¸¸åº”è¯¥è¢«æ­£ç¡®æ•è·
            assert result.get("success") is False
            assert "error" in result


class TestCommitErrors:
    """æäº¤é˜¶æ®µé”™è¯¯æµ‹è¯•"""

    @pytest.fixture
    def orchestrator_with_commit(self) -> Orchestrator:
        """åˆ›å»ºå¯ç”¨è‡ªåŠ¨æäº¤çš„ Orchestrator"""
        config = OrchestratorConfig(
            working_directory=".",
            max_iterations=1,
            worker_pool_size=1,
            enable_auto_commit=True,
            commit_on_complete=True,
        )
        return Orchestrator(config)

    @pytest.mark.asyncio
    async def test_commit_without_changes(self, orchestrator_with_commit: Orchestrator) -> None:
        """æ— å˜æ›´æäº¤ - ä¸åº”ä¸­æ–­ä¸»æµç¨‹ï¼Œé”™è¯¯åº”è®°å½•åˆ° iteration"""
        orchestrator = orchestrator_with_commit

        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "analyze",
                    "title": "åˆ†æä»»åŠ¡",
                    "description": "åªåˆ†æä¸ä¿®æ”¹",
                    "instruction": "åˆ†æä»£ç ",
                    "target_files": [],
                },
            ],
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 100,
            "summary": "åˆ†æå®Œæˆ",
        }

        # æ¨¡æ‹Ÿæ— å˜æ›´
        mock_commit_result = {
            "success": False,
            "error": "æ²¡æœ‰éœ€è¦æäº¤çš„å˜æ›´",
            "message": "",
            "files_changed": [],
            "pushed": False,
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            async def simulate_complete(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.complete({"output": "åˆ†æå®Œæˆ"})

            mock_workers.side_effect = simulate_complete

            # Mock committer
            if orchestrator.committer:
                with patch.object(orchestrator.committer, "commit_iteration", new_callable=AsyncMock) as mock_commit:
                    mock_commit.return_value = mock_commit_result

                    result = await orchestrator.run("æ— å˜æ›´æäº¤æµ‹è¯•")

                    # éªŒè¯æäº¤è¢«è°ƒç”¨ä½†è¿”å›æ— å˜æ›´
                    mock_commit.assert_called_once()

                    # éªŒè¯ä¸»æµç¨‹æœªä¸­æ–­ï¼Œç›®æ ‡ä»ç„¶å®Œæˆ
                    assert result["success"] is True

                    # éªŒè¯ commit_error è¢«æ­£ç¡®è®°å½•åˆ° iteration
                    assert len(result["iterations"]) == 1
                    iteration_result = result["iterations"][0]
                    assert iteration_result["commit_error"] == "æ²¡æœ‰éœ€è¦æäº¤çš„å˜æ›´"
                    assert iteration_result["commit_hash"] == ""
                    assert iteration_result["commit_pushed"] is False

    @pytest.mark.asyncio
    async def test_commit_conflict(self, orchestrator_with_commit: Orchestrator) -> None:
        """æäº¤å†²çªå¤„ç† - ä¸åº”ä¸­æ–­ä¸»æµç¨‹ï¼Œé”™è¯¯åº”è®°å½•åˆ° iteration"""
        orchestrator = orchestrator_with_commit

        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "å®ç°ä»»åŠ¡",
                    "description": "å®ç°åŠŸèƒ½",
                    "instruction": "åˆ›å»ºæ–‡ä»¶",
                    "target_files": ["conflict.py"],
                },
            ],
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 90,
            "summary": "ä»»åŠ¡å®Œæˆ",
        }

        # æ¨¡æ‹Ÿæäº¤å†²çª
        mock_commit_result = {
            "success": False,
            "error": "åˆå¹¶å†²çª: æ— æ³•è‡ªåŠ¨åˆå¹¶",
            "message": "",
            "files_changed": ["conflict.py"],
            "pushed": False,
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            async def simulate_complete(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.complete({"output": "å®Œæˆ"})

            mock_workers.side_effect = simulate_complete

            if orchestrator.committer:
                with patch.object(orchestrator.committer, "commit_iteration", new_callable=AsyncMock) as mock_commit:
                    mock_commit.return_value = mock_commit_result

                    result = await orchestrator.run("å†²çªæäº¤æµ‹è¯•")

                    # éªŒè¯æäº¤è¢«è°ƒç”¨
                    mock_commit.assert_called_once()

                    # éªŒè¯ä¸»æµç¨‹æœªä¸­æ–­ï¼Œç›®æ ‡ä»ç„¶å®Œæˆ
                    assert result["success"] is True

                    # éªŒè¯ commit_error è¢«æ­£ç¡®è®°å½•åˆ° iteration
                    assert len(result["iterations"]) == 1
                    iteration_result = result["iterations"][0]
                    assert iteration_result["commit_error"] == "åˆå¹¶å†²çª: æ— æ³•è‡ªåŠ¨åˆå¹¶"
                    assert iteration_result["commit_pushed"] is False

    @pytest.mark.asyncio
    async def test_push_failure(self, orchestrator_with_commit: Orchestrator) -> None:
        """æ¨é€å¤±è´¥å¤„ç† - æäº¤æˆåŠŸä½† pushed=Falseï¼Œpush_error åº”è®°å½•åˆ° iteration"""
        orchestrator = orchestrator_with_commit
        orchestrator.config.auto_push = True

        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "å®ç°ä»»åŠ¡",
                    "description": "å®ç°åŠŸèƒ½",
                    "instruction": "åˆ›å»ºæ–‡ä»¶",
                    "target_files": ["push_fail.py"],
                },
            ],
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 90,
            "summary": "ä»»åŠ¡å®Œæˆ",
        }

        # æäº¤æˆåŠŸä½†æ¨é€å¤±è´¥
        mock_commit_result = {
            "success": True,
            "commit_hash": "abc123def456",
            "message": "feat: å®ç°åŠŸèƒ½",
            "files_changed": ["push_fail.py"],
            "pushed": False,
            "push_error": "è¿œç¨‹ä»“åº“æ‹’ç»: æƒé™ä¸è¶³",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            async def simulate_complete(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.complete({"output": "å®Œæˆ"})

            mock_workers.side_effect = simulate_complete

            if orchestrator.committer:
                with patch.object(orchestrator.committer, "commit_iteration", new_callable=AsyncMock) as mock_commit:
                    mock_commit.return_value = mock_commit_result

                    result = await orchestrator.run("æ¨é€å¤±è´¥æµ‹è¯•")

                    # éªŒè¯æäº¤è¢«è°ƒç”¨
                    mock_commit.assert_called_once()

                    # éªŒè¯ä¸»æµç¨‹æœªä¸­æ–­ï¼Œç›®æ ‡ä»ç„¶å®Œæˆ
                    assert result["success"] is True

                    # éªŒè¯ iteration ä¸­è®°å½•äº†æ­£ç¡®çš„ä¿¡æ¯
                    assert len(result["iterations"]) == 1
                    iteration_result = result["iterations"][0]

                    # æäº¤æˆåŠŸæ—¶ commit_error åº”ä¸º None
                    assert iteration_result["commit_error"] is None

                    # commit_hash åº”è¢«è®°å½•
                    assert iteration_result["commit_hash"] == "abc123def456"

                    # pushed åº”ä¸º False
                    assert iteration_result["commit_pushed"] is False

                    # push_error åº”è¢«è®°å½•
                    assert iteration_result["push_error"] == "è¿œç¨‹ä»“åº“æ‹’ç»: æƒé™ä¸è¶³"

                    # æœ€ç»ˆç»“æœçš„ pushed å­—æ®µåº”ä¸º Falseï¼ˆæ— æˆåŠŸæ¨é€çš„æäº¤ï¼‰
                    assert result["pushed"] is False


class TestBoundaryConditions:
    """è¾¹ç•Œæ¡ä»¶æµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_zero_max_iterations(self) -> None:
        """max_iterations=0"""
        config = OrchestratorConfig(
            working_directory=".",
            max_iterations=0,  # 0 æ¬¡è¿­ä»£
            worker_pool_size=1,
            enable_auto_commit=False,
        )
        orchestrator = Orchestrator(config)

        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "ä»»åŠ¡",
                    "description": "æè¿°",
                    "instruction": "æ‰§è¡Œ",
                    "target_files": ["file.py"],
                },
            ],
        }

        with patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner:
            mock_planner.return_value = mock_plan_result

            result = await orchestrator.run("é›¶è¿­ä»£æµ‹è¯•")

            # max_iterations=0 åº”è¯¥ä¸æ‰§è¡Œä»»ä½•è¿­ä»£
            assert result["iterations_completed"] == 0
            # è§„åˆ’ä¸åº”è¯¥è¢«è°ƒç”¨
            mock_planner.assert_not_called()

    @pytest.mark.asyncio
    async def test_empty_goal(self) -> None:
        """ç©ºç›®æ ‡å­—ç¬¦ä¸²"""
        config = OrchestratorConfig(
            working_directory=".",
            max_iterations=1,
            worker_pool_size=1,
            enable_auto_commit=False,
        )
        orchestrator = Orchestrator(config)

        mock_plan_result = {
            "success": True,
            "tasks": [],
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 100,
            "summary": "ç©ºç›®æ ‡",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            # æµ‹è¯•ç©ºå­—ç¬¦ä¸²ç›®æ ‡
            result = await orchestrator.run("")

            # ç³»ç»Ÿåº”è¯¥èƒ½å¤„ç†ç©ºç›®æ ‡
            assert "iterations_completed" in result

    @pytest.mark.asyncio
    async def test_very_long_goal(self) -> None:
        """è¶…é•¿ç›®æ ‡å­—ç¬¦ä¸²"""
        config = OrchestratorConfig(
            working_directory=".",
            max_iterations=1,
            worker_pool_size=1,
            enable_auto_commit=False,
        )
        orchestrator = Orchestrator(config)

        # ç”Ÿæˆè¶…é•¿ç›®æ ‡å­—ç¬¦ä¸²ï¼ˆ10KBï¼‰
        very_long_goal = "è¿™æ˜¯ä¸€ä¸ªè¶…é•¿çš„ç›®æ ‡æè¿°ã€‚" * 1000

        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "å¤„ç†è¶…é•¿ç›®æ ‡",
                    "description": "ä»»åŠ¡æè¿°",
                    "instruction": "æ‰§è¡Œä»»åŠ¡",
                    "target_files": ["long.py"],
                },
            ],
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 100,
            "summary": "å®Œæˆ",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            async def simulate_complete(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.complete({"output": "å®Œæˆ"})

            mock_workers.side_effect = simulate_complete

            result = await orchestrator.run(very_long_goal)

            # ç³»ç»Ÿåº”è¯¥èƒ½å¤„ç†è¶…é•¿ç›®æ ‡
            assert result["goal"] == very_long_goal
            assert "iterations_completed" in result

    @pytest.mark.asyncio
    async def test_special_characters_in_goal(self) -> None:
        """ç›®æ ‡å«ç‰¹æ®Šå­—ç¬¦"""
        config = OrchestratorConfig(
            working_directory=".",
            max_iterations=1,
            worker_pool_size=1,
            enable_auto_commit=False,
        )
        orchestrator = Orchestrator(config)

        # åŒ…å«å„ç§ç‰¹æ®Šå­—ç¬¦çš„ç›®æ ‡
        special_goal = "å®ç°åŠŸèƒ½ï¼šåŒ…å«'å¼•å·'ã€\"åŒå¼•å·\"ã€`åå¼•å·`ã€\næ¢è¡Œç¬¦ã€\tåˆ¶è¡¨ç¬¦ã€ğŸ‰è¡¨æƒ…ç¬¦å·ã€<html>æ ‡ç­¾</html>ã€$å˜é‡ã€%æ ¼å¼åŒ–%"

        mock_plan_result = {
            "success": True,
            "tasks": [
                {
                    "type": "implement",
                    "title": "å¤„ç†ç‰¹æ®Šå­—ç¬¦",
                    "description": "ä»»åŠ¡æè¿°",
                    "instruction": "æ‰§è¡Œä»»åŠ¡",
                    "target_files": ["special.py"],
                },
            ],
        }

        mock_review_result = {
            "success": True,
            "decision": ReviewDecision.COMPLETE,
            "score": 100,
            "summary": "å®Œæˆ",
        }

        with (
            patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
            patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
            patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
        ):
            mock_planner.return_value = mock_plan_result
            mock_reviewer.return_value = mock_review_result

            async def simulate_complete(queue: Any, iteration_id: int) -> None:
                tasks = queue.get_tasks_by_iteration(iteration_id)
                for task in tasks:
                    task.complete({"output": "å®Œæˆ"})

            mock_workers.side_effect = simulate_complete

            result = await orchestrator.run(special_goal)

            # ç³»ç»Ÿåº”è¯¥èƒ½å¤„ç†ç‰¹æ®Šå­—ç¬¦
            assert result["goal"] == special_goal
            assert "iterations_completed" in result

    @pytest.mark.asyncio
    async def test_concurrent_orchestrator_runs(self) -> None:
        """å¹¶å‘è¿è¡Œå¤šä¸ª Orchestrator"""

        async def create_and_run(index: int) -> dict[str, Any]:
            config = OrchestratorConfig(
                working_directory=".",
                max_iterations=1,
                worker_pool_size=1,
                enable_auto_commit=False,
            )
            orchestrator = Orchestrator(config)

            mock_plan_result = {
                "success": True,
                "tasks": [
                    {
                        "type": "implement",
                        "title": f"å¹¶å‘ä»»åŠ¡{index}",
                        "description": f"ç¬¬{index}ä¸ªå¹¶å‘ä»»åŠ¡",
                        "instruction": f"æ‰§è¡Œä»»åŠ¡{index}",
                        "target_files": [f"concurrent_{index}.py"],
                    },
                ],
            }

            mock_review_result = {
                "success": True,
                "decision": ReviewDecision.COMPLETE,
                "score": 100,
                "summary": f"å¹¶å‘{index}å®Œæˆ",
            }

            with (
                patch.object(orchestrator.planner, "execute", new_callable=AsyncMock) as mock_planner,
                patch.object(orchestrator.worker_pool, "start", new_callable=AsyncMock) as mock_workers,
                patch.object(orchestrator.reviewer, "review_iteration", new_callable=AsyncMock) as mock_reviewer,
            ):
                mock_planner.return_value = mock_plan_result
                mock_reviewer.return_value = mock_review_result

                async def simulate_complete(queue: Any, iteration_id: int) -> None:
                    # æ·»åŠ éšæœºå»¶è¿Ÿæ¨¡æ‹ŸçœŸå®æ‰§è¡Œ
                    await asyncio.sleep(0.01 * index)
                    tasks = queue.get_tasks_by_iteration(iteration_id)
                    for task in tasks:
                        task.complete({"output": f"å®Œæˆ{index}"})

                mock_workers.side_effect = simulate_complete

                return await orchestrator.run(f"å¹¶å‘æµ‹è¯•{index}")

        # å¹¶å‘è¿è¡Œ 5 ä¸ª Orchestrator
        tasks = [create_and_run(i) for i in range(5)]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # éªŒè¯æ‰€æœ‰å¹¶å‘è¿è¡Œéƒ½æˆåŠŸå®Œæˆ
        for i, result in enumerate(results):
            if isinstance(result, BaseException):
                pytest.fail(f"å¹¶å‘è¿è¡Œ {i} æŠ›å‡ºå¼‚å¸¸: {result}")
            else:
                assert result["success"] is True, f"å¹¶å‘è¿è¡Œ {i} å¤±è´¥"
                assert result["iterations_completed"] == 1
